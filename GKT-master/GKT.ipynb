{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import networkx as nx\n",
    "\n",
    "# 데이터 로드\n",
    "learner_data_path = r'D:\\다운로드\\thirdstu.csv'\n",
    "relationship_data_path = r'D:\\다운로드\\label.csv'\n",
    "\n",
    "learner_data = pd.read_csv(learner_data_path)\n",
    "relationship_data = pd.read_csv(relationship_data_path)\n",
    "\n",
    "# 'A'를 제거하고 고유한 숫자 ID로 변환\n",
    "learner_data['assessmentItemID'] = learner_data['assessmentItemID'].apply(lambda x: int(x[1:]))\n",
    "\n",
    "# assessmentItemID의 최대값을 확인\n",
    "max_assessment_id = learner_data['assessmentItemID'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 생성 함수\n",
    "def create_graph(relationship_data):\n",
    "    graph = nx.DiGraph()\n",
    "    for _, row in relationship_data.iterrows():\n",
    "        from_node = row['from_id']\n",
    "        to_node = row['to_id']\n",
    "        graph.add_node(from_node)\n",
    "        graph.add_node(to_node)\n",
    "        graph.add_edge(from_node, to_node, weight=1.0)  # 가중치 기본값 1.0\n",
    "    return graph\n",
    "\n",
    "graph = create_graph(relationship_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 클래스 정의\n",
    "class LearnerDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.groups = data.groupby('learnerID')\n",
    "        self.responses = []\n",
    "\n",
    "        # 각 학습자의 데이터를 정리\n",
    "        for _, group in self.groups:\n",
    "            group = group.sort_values('assessmentItemID')  # 평가 문항 ID 순으로 정렬\n",
    "            questions = group['assessmentItemID'].tolist()\n",
    "            answers = group['answerCode'].tolist()\n",
    "\n",
    "            # 정수형으로 변환\n",
    "            questions = list(map(int, questions))\n",
    "            answers = list(map(int, answers))\n",
    "\n",
    "            self.responses.append(list(zip(questions, answers)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.responses)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        questions, answers = zip(*self.responses[idx])\n",
    "        questions = torch.tensor(questions, dtype=torch.long)\n",
    "        answers = torch.tensor(answers, dtype=torch.float)\n",
    "        return questions, answers\n",
    "\n",
    "# 패딩 및 데이터 로더 정의\n",
    "def collate_fn(batch):\n",
    "    questions = [item[0] for item in batch]\n",
    "    answers = [item[1] for item in batch]\n",
    "    questions_padded = pad_sequence(questions, batch_first=True, padding_value=0)\n",
    "    answers_padded = pad_sequence(answers, batch_first=True, padding_value=0)\n",
    "    return questions_padded, answers_padded\n",
    "\n",
    "# 학습자 데이터 로더 준비\n",
    "batch_size = 8  # 배치 크기를 줄임\n",
    "learner_dataset = LearnerDataset(learner_data)\n",
    "learner_loader = DataLoader(learner_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GKT 모델 정의\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GKT(nn.Module):\n",
    "    def __init__(self, ku_num, graph, latent_dim=64, hidden_num=64, dropout=0.2, max_assessment_id=1000):\n",
    "        super(GKT, self).__init__()\n",
    "        self.ku_num = ku_num\n",
    "        self.hidden_num = hidden_num\n",
    "        self.latent_dim = latent_dim\n",
    "        self.graph = graph\n",
    "\n",
    "        # 임베딩 크기를 max_assessment_id + 1로 설정하여 인덱스 초과를 방지\n",
    "        self.rnn = nn.GRU(input_size=latent_dim, hidden_size=hidden_num, batch_first=True)\n",
    "        self.response_embedding = nn.Embedding(2 * (max_assessment_id + 1), latent_dim)\n",
    "        self.concept_embedding = nn.Embedding(max_assessment_id + 1, latent_dim)\n",
    "        self.f_self = nn.Linear(hidden_num + latent_dim, hidden_num)\n",
    "        self.n_out = nn.Linear(hidden_num + latent_dim, hidden_num)\n",
    "        self.n_in = nn.Linear(hidden_num + latent_dim, hidden_num)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(hidden_num, 1)\n",
    "\n",
    "    def forward(self, questions, answers):\n",
    "        batch_size, seq_len = questions.size()\n",
    "        device = questions.device\n",
    "\n",
    "        h0 = torch.zeros(1, batch_size, self.hidden_num).to(device)\n",
    "        embedded_questions = self.concept_embedding(questions)\n",
    "        embedded_answers = self.response_embedding(answers.long() + questions * 2)\n",
    "\n",
    "        rnn_input = embedded_answers\n",
    "        outputs, _ = self.rnn(rnn_input, h0)\n",
    "\n",
    "        outputs = self.out(self.dropout(outputs)).squeeze(-1)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 7.20 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(data_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 모델 학습 실행\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mtrain_gkt_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgkt_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearner_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m, in \u001b[0;36mtrain_gkt_model\u001b[1;34m(model, data_loader, epochs)\u001b[0m\n\u001b[0;32m     20\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, answers)\n\u001b[0;32m     21\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 22\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(data_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\DLHK\\Lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\DLHK\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\DLHK\\Lib\\site-packages\\torch\\optim\\adam.py:159\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    156\u001b[0m     state_steps \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     adam(\n\u001b[0;32m    169\u001b[0m         params_with_grad,\n\u001b[0;32m    170\u001b[0m         grads,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    189\u001b[0m     )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\DLHK\\Lib\\site-packages\\torch\\optim\\adam.py:113\u001b[0m, in \u001b[0;36mAdam._init_group\u001b[1;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[0;32m    107\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m     torch\u001b[38;5;241m.\u001b[39mzeros((), dtype\u001b[38;5;241m=\u001b[39m_get_scalar_dtype(is_fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m]), device\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m_get_scalar_dtype())\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Exponential moving average of gradient values\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp_avg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[0;32m    115\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 7.20 GiB. GPU "
     ]
    }
   ],
   "source": [
    "# 모델 초기화 및 학습\n",
    "ku_num = len(graph.nodes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "gkt_model = GKT(ku_num=ku_num, graph=graph, latent_dim=32, hidden_num=32, dropout=0.2, max_assessment_id=max_assessment_id).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(gkt_model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 학습 함수\n",
    "def train_gkt_model(model, data_loader, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for questions, answers in data_loader:\n",
    "            questions, answers = questions.to(device), answers.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(questions, answers)\n",
    "            loss = criterion(outputs, answers)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}, Loss: {epoch_loss / len(data_loader)}')\n",
    "\n",
    "# 모델 학습 실행\n",
    "train_gkt_model(gkt_model, learner_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.60 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 156\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(data_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# 모델 학습 실행\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m \u001b[43mtrain_gkt_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgkt_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearner_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 143\u001b[0m, in \u001b[0;36mtrain_gkt_model\u001b[1;34m(model, data_loader, epochs, accumulation_steps)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Gradient Accumulation 적용\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_loader):\n\u001b[1;32m--> 143\u001b[0m     \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m    145\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\DLHK\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:453\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    451\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 453\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\DLHK\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m--> 351\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\DLHK\\Lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\DLHK\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\DLHK\\Lib\\site-packages\\torch\\optim\\adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    160\u001b[0m         group,\n\u001b[0;32m    161\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    166\u001b[0m         state_steps)\n\u001b[1;32m--> 168\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\DLHK\\Lib\\site-packages\\torch\\optim\\adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 318\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\DLHK\\Lib\\site-packages\\torch\\optim\\adam.py:581\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    579\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_max_exp_avg_sqs)\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[0;32m    584\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.60 GiB. GPU "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import networkx as nx\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import gc\n",
    "\n",
    "# 데이터 로드\n",
    "learner_data_path = r'D:\\다운로드\\thirdstu.csv'\n",
    "relationship_data_path = r'D:\\다운로드\\label.csv'\n",
    "\n",
    "learner_data = pd.read_csv(learner_data_path)\n",
    "relationship_data = pd.read_csv(relationship_data_path)\n",
    "\n",
    "# 'A'를 제거하고 고유한 숫자 ID로 변환\n",
    "learner_data['assessmentItemID'] = learner_data['assessmentItemID'].apply(lambda x: int(x[1:]))\n",
    "\n",
    "# assessmentItemID의 최대값을 확인\n",
    "max_assessment_id = learner_data['assessmentItemID'].max()\n",
    "\n",
    "# 그래프 생성 함수\n",
    "def create_graph(relationship_data):\n",
    "    graph = nx.DiGraph()\n",
    "    for _, row in relationship_data.iterrows():\n",
    "        from_node = row['from_id']\n",
    "        to_node = row['to_id']\n",
    "        graph.add_node(from_node)\n",
    "        graph.add_node(to_node)\n",
    "        graph.add_edge(from_node, to_node, weight=1.0)  # 가중치 기본값 1.0\n",
    "    return graph\n",
    "\n",
    "graph = create_graph(relationship_data)\n",
    "\n",
    "# Dataset 클래스 정의\n",
    "class LearnerDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.groups = data.groupby('learnerID')\n",
    "        self.responses = []\n",
    "\n",
    "        # 각 학습자의 데이터를 정리\n",
    "        for _, group in self.groups:\n",
    "            group = group.sort_values('assessmentItemID')  # 평가 문항 ID 순으로 정렬\n",
    "            questions = group['assessmentItemID'].tolist()\n",
    "            answers = group['answerCode'].tolist()\n",
    "\n",
    "            # 정수형으로 변환\n",
    "            questions = list(map(int, questions))\n",
    "            answers = list(map(int, answers))\n",
    "\n",
    "            self.responses.append(list(zip(questions, answers)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.responses)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        questions, answers = zip(*self.responses[idx])\n",
    "        questions = torch.tensor(questions, dtype=torch.long)\n",
    "        answers = torch.tensor(answers, dtype=torch.float)\n",
    "        return questions, answers\n",
    "\n",
    "# 패딩 및 데이터 로더 정의\n",
    "def collate_fn(batch):\n",
    "    questions = [item[0] for item in batch]\n",
    "    answers = [item[1] for item in batch]\n",
    "    questions_padded = pad_sequence(questions, batch_first=True, padding_value=0)\n",
    "    answers_padded = pad_sequence(answers, batch_first=True, padding_value=0)\n",
    "    return questions_padded, answers_padded\n",
    "\n",
    "# 학습자 데이터 로더 준비\n",
    "batch_size = 2  # 배치 크기를 가능한 최소값으로 줄임\n",
    "learner_dataset = LearnerDataset(learner_data)\n",
    "learner_loader = DataLoader(learner_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "# GKT 모델 정의\n",
    "import torch.nn as nn\n",
    "\n",
    "class GKT(nn.Module):\n",
    "    def __init__(self, ku_num, graph, latent_dim=16, hidden_num=16, dropout=0.2, max_assessment_id=1000):\n",
    "        super(GKT, self).__init__()\n",
    "        self.ku_num = ku_num\n",
    "        self.hidden_num = hidden_num\n",
    "        self.latent_dim = latent_dim\n",
    "        self.graph = graph\n",
    "\n",
    "        # 임베딩 크기를 max_assessment_id + 1로 설정하여 인덱스 초과를 방지\n",
    "        self.rnn = nn.GRU(input_size=latent_dim, hidden_size=hidden_num, batch_first=True)\n",
    "        self.response_embedding = nn.Embedding(2 * (max_assessment_id + 1), latent_dim)\n",
    "        self.concept_embedding = nn.Embedding(max_assessment_id + 1, latent_dim)\n",
    "        self.f_self = nn.Linear(hidden_num + latent_dim, hidden_num)\n",
    "        self.n_out = nn.Linear(hidden_num + latent_dim, hidden_num)\n",
    "        self.n_in = nn.Linear(hidden_num + latent_dim, hidden_num)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(hidden_num, 1)\n",
    "\n",
    "    def forward(self, questions, answers):\n",
    "        batch_size, seq_len = questions.size()\n",
    "        device = questions.device\n",
    "\n",
    "        h0 = torch.zeros(1, batch_size, self.hidden_num).to(device)\n",
    "        embedded_questions = self.concept_embedding(questions)\n",
    "        embedded_answers = self.response_embedding(answers.long() + questions * 2)\n",
    "\n",
    "        rnn_input = embedded_answers\n",
    "        outputs, _ = self.rnn(rnn_input, h0)\n",
    "\n",
    "        outputs = self.out(self.dropout(outputs)).squeeze(-1)\n",
    "        # BCEWithLogitsLoss를 사용하므로 시그모이드 적용하지 않음\n",
    "        return outputs\n",
    "\n",
    "# 모델 초기화 및 학습\n",
    "ku_num = len(graph.nodes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gkt_model = GKT(ku_num=ku_num, graph=graph, latent_dim=16, hidden_num=16, dropout=0.2, max_assessment_id=max_assessment_id).to(device)\n",
    "\n",
    "# 손실 함수를 BCEWithLogitsLoss로 변경\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(gkt_model.parameters(), lr=0.001)\n",
    "\n",
    "# Mixed Precision Training을 위한 GradScaler 초기화\n",
    "scaler = GradScaler()\n",
    "\n",
    "# 모델 학습 함수\n",
    "def train_gkt_model(model, data_loader, epochs=10, accumulation_steps=4):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        for i, (questions, answers) in enumerate(data_loader):\n",
    "            questions, answers = questions.to(device), answers.to(device)\n",
    "\n",
    "            # Mixed Precision Training 사용\n",
    "            with autocast():\n",
    "                outputs = model(questions, answers)\n",
    "                loss = criterion(outputs, answers) / accumulation_steps\n",
    "\n",
    "            # 스케일링을 통한 역전파 및 최적화\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # Gradient Accumulation 적용\n",
    "            if (i + 1) % accumulation_steps == 0 or (i + 1) == len(data_loader):\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # 메모리 관리 및 캐시 정리\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}, Loss: {epoch_loss / len(data_loader)}')\n",
    "\n",
    "# 모델 학습 실행\n",
    "train_gkt_model(gkt_model, learner_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    learnerID assessmentItemID  answerCode  knowledgeTag  from_id  \\\n",
      "0  A030000005       A030001001           1           307    307.0   \n",
      "1  A030000005       A030001001           1           307    307.0   \n",
      "2  A030000005       A030001001           1           307    307.0   \n",
      "3  A030000005       A030001002           1           307    307.0   \n",
      "4  A030000005       A030001002           1           307    307.0   \n",
      "\n",
      "                     from_name from_semester  \\\n",
      "0  받아 내림이 없는 $(세 자릿수)-(세 자릿수)$     초등-초3-1학기   \n",
      "1  받아 내림이 없는 $(세 자릿수)-(세 자릿수)$     초등-초3-1학기   \n",
      "2  받아 내림이 없는 $(세 자릿수)-(세 자릿수)$     초등-초3-1학기   \n",
      "3  받아 내림이 없는 $(세 자릿수)-(세 자릿수)$     초등-초3-1학기   \n",
      "4  받아 내림이 없는 $(세 자릿수)-(세 자릿수)$     초등-초3-1학기   \n",
      "\n",
      "                                    from_description  from_chapter_id  \\\n",
      "0  1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...            149.0   \n",
      "1  1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...            149.0   \n",
      "2  1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...            149.0   \n",
      "3  1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...            149.0   \n",
      "4  1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...            149.0   \n",
      "\n",
      "        from_chapter_name  from_achievement_id  \\\n",
      "0  덧셈과 뺄셈 > 뺄셈을 해 볼까요 (1)                 45.0   \n",
      "1  덧셈과 뺄셈 > 뺄셈을 해 볼까요 (1)                 45.0   \n",
      "2  덧셈과 뺄셈 > 뺄셈을 해 볼까요 (1)                 45.0   \n",
      "3  덧셈과 뺄셈 > 뺄셈을 해 볼까요 (1)                 45.0   \n",
      "4  덧셈과 뺄셈 > 뺄셈을 해 볼까요 (1)                 45.0   \n",
      "\n",
      "                               from_achievement_name   to_id        to_name  \\\n",
      "0  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  7797.0     (몇십 몇)-(몇)   \n",
      "1  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  7798.0      (몇십)-(몇십)   \n",
      "2  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  7799.0  (몇십 몇)-(몇십 몇)   \n",
      "3  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  7797.0     (몇십 몇)-(몇)   \n",
      "4  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  7798.0      (몇십)-(몇십)   \n",
      "\n",
      "  to_semester                                     to_description  \\\n",
      "0   초등-초1-2학기  (1) 낱개끼리  줄을 맞추어 씁니다.\\n(2) 낱개는 낱개끼리 빼고 10개씩 묶음...   \n",
      "1   초등-초1-2학기  (1) 10개씩 묶음은 10개씩 묶음끼리, 낱개는 낱개끼리 줄을 맞추어 씁니다.\\n...   \n",
      "2   초등-초1-2학기  (1) 10개씩 묶음은 10개씩 묶음끼리, 낱개는 낱개끼리 줄을 맞추어 씁니다.\\n...   \n",
      "3   초등-초1-2학기  (1) 낱개끼리  줄을 맞추어 씁니다.\\n(2) 낱개는 낱개끼리 빼고 10개씩 묶음...   \n",
      "4   초등-초1-2학기  (1) 10개씩 묶음은 10개씩 묶음끼리, 낱개는 낱개끼리 줄을 맞추어 씁니다.\\n...   \n",
      "\n",
      "   to_chapter_id            to_chapter_name  to_achievement_id  \\\n",
      "0           42.0  덧셈과 뺄셈(1) > 뺄셈을 해 볼까요 (1)               45.0   \n",
      "1           43.0  덧셈과 뺄셈(1) > 뺄셈을 해 볼까요 (2)               45.0   \n",
      "2           44.0  덧셈과 뺄셈(1) > 뺄셈을 해 볼까요 (3)               45.0   \n",
      "3           42.0  덧셈과 뺄셈(1) > 뺄셈을 해 볼까요 (1)               45.0   \n",
      "4           43.0  덧셈과 뺄셈(1) > 뺄셈을 해 볼까요 (2)               45.0   \n",
      "\n",
      "                                 to_achievement_name  \n",
      "0  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  \n",
      "1  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  \n",
      "2  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  \n",
      "3  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  \n",
      "4  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  \n",
      "Epoch 1, Loss: 0.5972, Accuracy: 0.7155\n",
      "Epoch 2, Loss: 0.5976, Accuracy: 0.7155\n",
      "Epoch 3, Loss: 0.5984, Accuracy: 0.7155\n",
      "Epoch 4, Loss: 0.5972, Accuracy: 0.7155\n",
      "Epoch 5, Loss: 0.5972, Accuracy: 0.7155\n",
      "Epoch 6, Loss: 0.5972, Accuracy: 0.7155\n",
      "Epoch 7, Loss: 0.5972, Accuracy: 0.7155\n",
      "Epoch 8, Loss: 0.5972, Accuracy: 0.7155\n",
      "Epoch 9, Loss: 0.5972, Accuracy: 0.7155\n",
      "Epoch 10, Loss: 0.5972, Accuracy: 0.7155\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 데이터 불러오기\n",
    "label_data = pd.read_csv(r'D:\\다운로드\\label.csv')\n",
    "thirdstu_data = pd.read_csv(r'D:\\다운로드\\thirdstu.csv')\n",
    "\n",
    "# 데이터 전처리\n",
    "edges = label_data[['from_id', 'to_id']].drop_duplicates()\n",
    "nodes = pd.concat([edges['from_id'], edges['to_id']]).unique()\n",
    "learner_data = thirdstu_data[['learnerID', 'assessmentItemID', 'answerCode', 'knowledgeTag']]\n",
    "merged_data = learner_data.merge(label_data, left_on='knowledgeTag', right_on='from_id', how='left')\n",
    "print(merged_data.head())\n",
    "\n",
    "# 훈련 및 테스트 데이터 분리\n",
    "train_data, test_data = train_test_split(merged_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 그래프 생성\n",
    "graph = nx.DiGraph()\n",
    "graph.add_nodes_from(nodes)\n",
    "graph.add_edges_from(edges.values)\n",
    "\n",
    "# 임베딩 학습\n",
    "stellar_graph = StellarGraph.from_networkx(graph)\n",
    "rw = BiasedRandomWalk(stellar_graph)\n",
    "walks = rw.run(nodes=list(graph.nodes()), length=100, n=10, p=0.5, q=2.0)\n",
    "str_walks = [[str(n) for n in walk] for walk in walks]\n",
    "model = Word2Vec(str_walks, vector_size=128, window=5, min_count=1, sg=1, workers=4)\n",
    "node_embeddings = {node: model.wv[str(node)] for node in graph.nodes()}\n",
    "\n",
    "# 임베딩 데이터를 활용한 입력 생성 함수\n",
    "def create_input_data(data, node_embeddings):\n",
    "    X = np.array([node_embeddings.get(str(item), np.zeros(128)) for item in data['assessmentItemID']])\n",
    "    y = data['answerCode'].values\n",
    "    return X, y\n",
    "\n",
    "# 훈련 및 테스트 데이터 준비\n",
    "X_train, y_train = create_input_data(train_data, node_embeddings)\n",
    "X_test, y_test = create_input_data(test_data, node_embeddings)\n",
    "\n",
    "# LSTM에 입력할 데이터를 3차원으로 변환\n",
    "X_train = np.expand_dims(X_train, axis=1)  # (batch_size, time_steps, features)\n",
    "X_test = np.expand_dims(X_test, axis=1)\n",
    "\n",
    "# PyTorch 데이터셋 및 데이터로더 생성\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# PyTorch 모델 정의\n",
    "class KSGKTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KSGKTModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=256, batch_first=True)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=256, num_heads=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = lstm_out.permute(1, 0, 2)  # LSTM output shape adjustment for attention\n",
    "        attn_output, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
    "        attn_output = attn_output.permute(1, 0, 2)  # Shape back to (batch, seq, feature)\n",
    "        flatten_out = self.flatten(attn_output)\n",
    "        x = torch.relu(self.fc1(flatten_out))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# 모델 초기화\n",
    "model = KSGKTModel()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 학습 함수\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    for data, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 모델 평가 함수\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    loss_total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss_total += loss.item()\n",
    "            preds = (outputs.squeeze() > 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    return loss_total / len(test_loader), accuracy\n",
    "\n",
    "# 학습 및 평가 루프\n",
    "for epoch in range(10):\n",
    "    train(model, train_loader, criterion, optimizer)\n",
    "    loss, accuracy = evaluate(model, test_loader, criterion)\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learnerID</th>\n",
       "      <th>assessmentItemID</th>\n",
       "      <th>answerCode</th>\n",
       "      <th>knowledgeTag</th>\n",
       "      <th>from_id</th>\n",
       "      <th>from_name</th>\n",
       "      <th>from_semester</th>\n",
       "      <th>from_description</th>\n",
       "      <th>from_chapter_id</th>\n",
       "      <th>from_chapter_name</th>\n",
       "      <th>from_achievement_id</th>\n",
       "      <th>from_achievement_name</th>\n",
       "      <th>to_id</th>\n",
       "      <th>to_name</th>\n",
       "      <th>to_semester</th>\n",
       "      <th>to_description</th>\n",
       "      <th>to_chapter_id</th>\n",
       "      <th>to_chapter_name</th>\n",
       "      <th>to_achievement_id</th>\n",
       "      <th>to_achievement_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A030000005</td>\n",
       "      <td>A030001001</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>307.0</td>\n",
       "      <td>받아 내림이 없는 $(세 자릿수)-(세 자릿수)$</td>\n",
       "      <td>초등-초3-1학기</td>\n",
       "      <td>1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...</td>\n",
       "      <td>149.0</td>\n",
       "      <td>덧셈과 뺄셈 &gt; 뺄셈을 해 볼까요 (1)</td>\n",
       "      <td>45.0</td>\n",
       "      <td>두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...</td>\n",
       "      <td>7797.0</td>\n",
       "      <td>(몇십 몇)-(몇)</td>\n",
       "      <td>초등-초1-2학기</td>\n",
       "      <td>(1) 낱개끼리  줄을 맞추어 씁니다.\\n(2) 낱개는 낱개끼리 빼고 10개씩 묶음...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>덧셈과 뺄셈(1) &gt; 뺄셈을 해 볼까요 (1)</td>\n",
       "      <td>45.0</td>\n",
       "      <td>두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A030000005</td>\n",
       "      <td>A030001001</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>307.0</td>\n",
       "      <td>받아 내림이 없는 $(세 자릿수)-(세 자릿수)$</td>\n",
       "      <td>초등-초3-1학기</td>\n",
       "      <td>1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...</td>\n",
       "      <td>149.0</td>\n",
       "      <td>덧셈과 뺄셈 &gt; 뺄셈을 해 볼까요 (1)</td>\n",
       "      <td>45.0</td>\n",
       "      <td>두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...</td>\n",
       "      <td>7798.0</td>\n",
       "      <td>(몇십)-(몇십)</td>\n",
       "      <td>초등-초1-2학기</td>\n",
       "      <td>(1) 10개씩 묶음은 10개씩 묶음끼리, 낱개는 낱개끼리 줄을 맞추어 씁니다.\\n...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>덧셈과 뺄셈(1) &gt; 뺄셈을 해 볼까요 (2)</td>\n",
       "      <td>45.0</td>\n",
       "      <td>두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A030000005</td>\n",
       "      <td>A030001001</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>307.0</td>\n",
       "      <td>받아 내림이 없는 $(세 자릿수)-(세 자릿수)$</td>\n",
       "      <td>초등-초3-1학기</td>\n",
       "      <td>1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...</td>\n",
       "      <td>149.0</td>\n",
       "      <td>덧셈과 뺄셈 &gt; 뺄셈을 해 볼까요 (1)</td>\n",
       "      <td>45.0</td>\n",
       "      <td>두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...</td>\n",
       "      <td>7799.0</td>\n",
       "      <td>(몇십 몇)-(몇십 몇)</td>\n",
       "      <td>초등-초1-2학기</td>\n",
       "      <td>(1) 10개씩 묶음은 10개씩 묶음끼리, 낱개는 낱개끼리 줄을 맞추어 씁니다.\\n...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>덧셈과 뺄셈(1) &gt; 뺄셈을 해 볼까요 (3)</td>\n",
       "      <td>45.0</td>\n",
       "      <td>두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A030000005</td>\n",
       "      <td>A030001002</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>307.0</td>\n",
       "      <td>받아 내림이 없는 $(세 자릿수)-(세 자릿수)$</td>\n",
       "      <td>초등-초3-1학기</td>\n",
       "      <td>1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...</td>\n",
       "      <td>149.0</td>\n",
       "      <td>덧셈과 뺄셈 &gt; 뺄셈을 해 볼까요 (1)</td>\n",
       "      <td>45.0</td>\n",
       "      <td>두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...</td>\n",
       "      <td>7797.0</td>\n",
       "      <td>(몇십 몇)-(몇)</td>\n",
       "      <td>초등-초1-2학기</td>\n",
       "      <td>(1) 낱개끼리  줄을 맞추어 씁니다.\\n(2) 낱개는 낱개끼리 빼고 10개씩 묶음...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>덧셈과 뺄셈(1) &gt; 뺄셈을 해 볼까요 (1)</td>\n",
       "      <td>45.0</td>\n",
       "      <td>두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A030000005</td>\n",
       "      <td>A030001002</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>307.0</td>\n",
       "      <td>받아 내림이 없는 $(세 자릿수)-(세 자릿수)$</td>\n",
       "      <td>초등-초3-1학기</td>\n",
       "      <td>1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...</td>\n",
       "      <td>149.0</td>\n",
       "      <td>덧셈과 뺄셈 &gt; 뺄셈을 해 볼까요 (1)</td>\n",
       "      <td>45.0</td>\n",
       "      <td>두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...</td>\n",
       "      <td>7798.0</td>\n",
       "      <td>(몇십)-(몇십)</td>\n",
       "      <td>초등-초1-2학기</td>\n",
       "      <td>(1) 10개씩 묶음은 10개씩 묶음끼리, 낱개는 낱개끼리 줄을 맞추어 씁니다.\\n...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>덧셈과 뺄셈(1) &gt; 뺄셈을 해 볼까요 (2)</td>\n",
       "      <td>45.0</td>\n",
       "      <td>두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575612</th>\n",
       "      <td>A030003000</td>\n",
       "      <td>A030198004</td>\n",
       "      <td>0</td>\n",
       "      <td>1984</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>그림그래프</td>\n",
       "      <td>초등-초3-2학기</td>\n",
       "      <td>알려고 하는 수(조사한 수)를 그림으로 나타낸 그래프</td>\n",
       "      <td>219.0</td>\n",
       "      <td>자료의 정리 &gt; 그림그래프를 알아볼까요</td>\n",
       "      <td>295.0</td>\n",
       "      <td>실생활 자료를 수집하여 그림그래프로 나타낼 수 있다.</td>\n",
       "      <td>8135.0</td>\n",
       "      <td>자료를 보고 표로 나타내기</td>\n",
       "      <td>초등-초2-2학기</td>\n",
       "      <td>자료를 분류하여 분류한 종류에 맞게 수를 세어 표로 나타냅니다.\\n자료를 보고 바로...</td>\n",
       "      <td>135.0</td>\n",
       "      <td>표와 그래프 &gt; 자료를 보고 표로 나타내어 볼까요</td>\n",
       "      <td>293.0</td>\n",
       "      <td>분류한 자료를 표로 나타내고, 표로 나타내면 편리한 점을 말할 수 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575613</th>\n",
       "      <td>A030003000</td>\n",
       "      <td>A030198004</td>\n",
       "      <td>0</td>\n",
       "      <td>1984</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>그림그래프</td>\n",
       "      <td>초등-초3-2학기</td>\n",
       "      <td>알려고 하는 수(조사한 수)를 그림으로 나타낸 그래프</td>\n",
       "      <td>219.0</td>\n",
       "      <td>자료의 정리 &gt; 그림그래프를 알아볼까요</td>\n",
       "      <td>295.0</td>\n",
       "      <td>실생활 자료를 수집하여 그림그래프로 나타낼 수 있다.</td>\n",
       "      <td>8138.0</td>\n",
       "      <td>표와 그래프의 편리한 점</td>\n",
       "      <td>초등-초2-2학기</td>\n",
       "      <td>표는 종류별 자료의 수와 전체 자료의 수를 쉽게 알 수 있습니다.\\n그래프는 가장 ...</td>\n",
       "      <td>138.0</td>\n",
       "      <td>표와 그래프 &gt; 표와 그래프의 내용을 알아볼까요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575614</th>\n",
       "      <td>A030003000</td>\n",
       "      <td>A030198005</td>\n",
       "      <td>1</td>\n",
       "      <td>1984</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>그림그래프</td>\n",
       "      <td>초등-초3-2학기</td>\n",
       "      <td>알려고 하는 수(조사한 수)를 그림으로 나타낸 그래프</td>\n",
       "      <td>219.0</td>\n",
       "      <td>자료의 정리 &gt; 그림그래프를 알아볼까요</td>\n",
       "      <td>295.0</td>\n",
       "      <td>실생활 자료를 수집하여 그림그래프로 나타낼 수 있다.</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>자료를 수집하여 표로 나타내는 방법</td>\n",
       "      <td>초등-초3-2학기</td>\n",
       "      <td>1. 조사할 내용 정하기\\n2. 자료를 수집할 방법 정하기\\n3. 자료 수집하기\\n...</td>\n",
       "      <td>218.0</td>\n",
       "      <td>자료의 정리 &gt; 자료를 수집하여 표로 나타내어 볼까요</td>\n",
       "      <td>293.0</td>\n",
       "      <td>분류한 자료를 표로 나타내고, 표로 나타내면 편리한 점을 말할 수 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575615</th>\n",
       "      <td>A030003000</td>\n",
       "      <td>A030198005</td>\n",
       "      <td>1</td>\n",
       "      <td>1984</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>그림그래프</td>\n",
       "      <td>초등-초3-2학기</td>\n",
       "      <td>알려고 하는 수(조사한 수)를 그림으로 나타낸 그래프</td>\n",
       "      <td>219.0</td>\n",
       "      <td>자료의 정리 &gt; 그림그래프를 알아볼까요</td>\n",
       "      <td>295.0</td>\n",
       "      <td>실생활 자료를 수집하여 그림그래프로 나타낼 수 있다.</td>\n",
       "      <td>8135.0</td>\n",
       "      <td>자료를 보고 표로 나타내기</td>\n",
       "      <td>초등-초2-2학기</td>\n",
       "      <td>자료를 분류하여 분류한 종류에 맞게 수를 세어 표로 나타냅니다.\\n자료를 보고 바로...</td>\n",
       "      <td>135.0</td>\n",
       "      <td>표와 그래프 &gt; 자료를 보고 표로 나타내어 볼까요</td>\n",
       "      <td>293.0</td>\n",
       "      <td>분류한 자료를 표로 나타내고, 표로 나타내면 편리한 점을 말할 수 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575616</th>\n",
       "      <td>A030003000</td>\n",
       "      <td>A030198005</td>\n",
       "      <td>1</td>\n",
       "      <td>1984</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>그림그래프</td>\n",
       "      <td>초등-초3-2학기</td>\n",
       "      <td>알려고 하는 수(조사한 수)를 그림으로 나타낸 그래프</td>\n",
       "      <td>219.0</td>\n",
       "      <td>자료의 정리 &gt; 그림그래프를 알아볼까요</td>\n",
       "      <td>295.0</td>\n",
       "      <td>실생활 자료를 수집하여 그림그래프로 나타낼 수 있다.</td>\n",
       "      <td>8138.0</td>\n",
       "      <td>표와 그래프의 편리한 점</td>\n",
       "      <td>초등-초2-2학기</td>\n",
       "      <td>표는 종류별 자료의 수와 전체 자료의 수를 쉽게 알 수 있습니다.\\n그래프는 가장 ...</td>\n",
       "      <td>138.0</td>\n",
       "      <td>표와 그래프 &gt; 표와 그래프의 내용을 알아볼까요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575617 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         learnerID assessmentItemID  answerCode  knowledgeTag  from_id  \\\n",
       "0       A030000005       A030001001           1           307    307.0   \n",
       "1       A030000005       A030001001           1           307    307.0   \n",
       "2       A030000005       A030001001           1           307    307.0   \n",
       "3       A030000005       A030001002           1           307    307.0   \n",
       "4       A030000005       A030001002           1           307    307.0   \n",
       "...            ...              ...         ...           ...      ...   \n",
       "575612  A030003000       A030198004           0          1984   1984.0   \n",
       "575613  A030003000       A030198004           0          1984   1984.0   \n",
       "575614  A030003000       A030198005           1          1984   1984.0   \n",
       "575615  A030003000       A030198005           1          1984   1984.0   \n",
       "575616  A030003000       A030198005           1          1984   1984.0   \n",
       "\n",
       "                          from_name from_semester  \\\n",
       "0       받아 내림이 없는 $(세 자릿수)-(세 자릿수)$     초등-초3-1학기   \n",
       "1       받아 내림이 없는 $(세 자릿수)-(세 자릿수)$     초등-초3-1학기   \n",
       "2       받아 내림이 없는 $(세 자릿수)-(세 자릿수)$     초등-초3-1학기   \n",
       "3       받아 내림이 없는 $(세 자릿수)-(세 자릿수)$     초등-초3-1학기   \n",
       "4       받아 내림이 없는 $(세 자릿수)-(세 자릿수)$     초등-초3-1학기   \n",
       "...                             ...           ...   \n",
       "575612                        그림그래프     초등-초3-2학기   \n",
       "575613                        그림그래프     초등-초3-2학기   \n",
       "575614                        그림그래프     초등-초3-2학기   \n",
       "575615                        그림그래프     초등-초3-2학기   \n",
       "575616                        그림그래프     초등-초3-2학기   \n",
       "\n",
       "                                         from_description  from_chapter_id  \\\n",
       "0       1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...            149.0   \n",
       "1       1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...            149.0   \n",
       "2       1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...            149.0   \n",
       "3       1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...            149.0   \n",
       "4       1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...            149.0   \n",
       "...                                                   ...              ...   \n",
       "575612                      알려고 하는 수(조사한 수)를 그림으로 나타낸 그래프            219.0   \n",
       "575613                      알려고 하는 수(조사한 수)를 그림으로 나타낸 그래프            219.0   \n",
       "575614                      알려고 하는 수(조사한 수)를 그림으로 나타낸 그래프            219.0   \n",
       "575615                      알려고 하는 수(조사한 수)를 그림으로 나타낸 그래프            219.0   \n",
       "575616                      알려고 하는 수(조사한 수)를 그림으로 나타낸 그래프            219.0   \n",
       "\n",
       "             from_chapter_name  from_achievement_id  \\\n",
       "0       덧셈과 뺄셈 > 뺄셈을 해 볼까요 (1)                 45.0   \n",
       "1       덧셈과 뺄셈 > 뺄셈을 해 볼까요 (1)                 45.0   \n",
       "2       덧셈과 뺄셈 > 뺄셈을 해 볼까요 (1)                 45.0   \n",
       "3       덧셈과 뺄셈 > 뺄셈을 해 볼까요 (1)                 45.0   \n",
       "4       덧셈과 뺄셈 > 뺄셈을 해 볼까요 (1)                 45.0   \n",
       "...                        ...                  ...   \n",
       "575612   자료의 정리 > 그림그래프를 알아볼까요                295.0   \n",
       "575613   자료의 정리 > 그림그래프를 알아볼까요                295.0   \n",
       "575614   자료의 정리 > 그림그래프를 알아볼까요                295.0   \n",
       "575615   자료의 정리 > 그림그래프를 알아볼까요                295.0   \n",
       "575616   자료의 정리 > 그림그래프를 알아볼까요                295.0   \n",
       "\n",
       "                                    from_achievement_name   to_id  \\\n",
       "0       두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  7797.0   \n",
       "1       두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  7798.0   \n",
       "2       두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  7799.0   \n",
       "3       두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  7797.0   \n",
       "4       두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  7798.0   \n",
       "...                                                   ...     ...   \n",
       "575612                      실생활 자료를 수집하여 그림그래프로 나타낼 수 있다.  8135.0   \n",
       "575613                      실생활 자료를 수집하여 그림그래프로 나타낼 수 있다.  8138.0   \n",
       "575614                      실생활 자료를 수집하여 그림그래프로 나타낼 수 있다.  1983.0   \n",
       "575615                      실생활 자료를 수집하여 그림그래프로 나타낼 수 있다.  8135.0   \n",
       "575616                      실생활 자료를 수집하여 그림그래프로 나타낼 수 있다.  8138.0   \n",
       "\n",
       "                    to_name to_semester  \\\n",
       "0                (몇십 몇)-(몇)   초등-초1-2학기   \n",
       "1                 (몇십)-(몇십)   초등-초1-2학기   \n",
       "2             (몇십 몇)-(몇십 몇)   초등-초1-2학기   \n",
       "3                (몇십 몇)-(몇)   초등-초1-2학기   \n",
       "4                 (몇십)-(몇십)   초등-초1-2학기   \n",
       "...                     ...         ...   \n",
       "575612       자료를 보고 표로 나타내기   초등-초2-2학기   \n",
       "575613        표와 그래프의 편리한 점   초등-초2-2학기   \n",
       "575614  자료를 수집하여 표로 나타내는 방법   초등-초3-2학기   \n",
       "575615       자료를 보고 표로 나타내기   초등-초2-2학기   \n",
       "575616        표와 그래프의 편리한 점   초등-초2-2학기   \n",
       "\n",
       "                                           to_description  to_chapter_id  \\\n",
       "0       (1) 낱개끼리  줄을 맞추어 씁니다.\\n(2) 낱개는 낱개끼리 빼고 10개씩 묶음...           42.0   \n",
       "1       (1) 10개씩 묶음은 10개씩 묶음끼리, 낱개는 낱개끼리 줄을 맞추어 씁니다.\\n...           43.0   \n",
       "2       (1) 10개씩 묶음은 10개씩 묶음끼리, 낱개는 낱개끼리 줄을 맞추어 씁니다.\\n...           44.0   \n",
       "3       (1) 낱개끼리  줄을 맞추어 씁니다.\\n(2) 낱개는 낱개끼리 빼고 10개씩 묶음...           42.0   \n",
       "4       (1) 10개씩 묶음은 10개씩 묶음끼리, 낱개는 낱개끼리 줄을 맞추어 씁니다.\\n...           43.0   \n",
       "...                                                   ...            ...   \n",
       "575612  자료를 분류하여 분류한 종류에 맞게 수를 세어 표로 나타냅니다.\\n자료를 보고 바로...          135.0   \n",
       "575613  표는 종류별 자료의 수와 전체 자료의 수를 쉽게 알 수 있습니다.\\n그래프는 가장 ...          138.0   \n",
       "575614  1. 조사할 내용 정하기\\n2. 자료를 수집할 방법 정하기\\n3. 자료 수집하기\\n...          218.0   \n",
       "575615  자료를 분류하여 분류한 종류에 맞게 수를 세어 표로 나타냅니다.\\n자료를 보고 바로...          135.0   \n",
       "575616  표는 종류별 자료의 수와 전체 자료의 수를 쉽게 알 수 있습니다.\\n그래프는 가장 ...          138.0   \n",
       "\n",
       "                      to_chapter_name  to_achievement_id  \\\n",
       "0           덧셈과 뺄셈(1) > 뺄셈을 해 볼까요 (1)               45.0   \n",
       "1           덧셈과 뺄셈(1) > 뺄셈을 해 볼까요 (2)               45.0   \n",
       "2           덧셈과 뺄셈(1) > 뺄셈을 해 볼까요 (3)               45.0   \n",
       "3           덧셈과 뺄셈(1) > 뺄셈을 해 볼까요 (1)               45.0   \n",
       "4           덧셈과 뺄셈(1) > 뺄셈을 해 볼까요 (2)               45.0   \n",
       "...                               ...                ...   \n",
       "575612    표와 그래프 > 자료를 보고 표로 나타내어 볼까요              293.0   \n",
       "575613     표와 그래프 > 표와 그래프의 내용을 알아볼까요                NaN   \n",
       "575614  자료의 정리 > 자료를 수집하여 표로 나타내어 볼까요              293.0   \n",
       "575615    표와 그래프 > 자료를 보고 표로 나타내어 볼까요              293.0   \n",
       "575616     표와 그래프 > 표와 그래프의 내용을 알아볼까요                NaN   \n",
       "\n",
       "                                      to_achievement_name  \n",
       "0       두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  \n",
       "1       두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  \n",
       "2       두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  \n",
       "3       두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  \n",
       "4       두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  \n",
       "...                                                   ...  \n",
       "575612           분류한 자료를 표로 나타내고, 표로 나타내면 편리한 점을 말할 수 있다.  \n",
       "575613                                                NaN  \n",
       "575614           분류한 자료를 표로 나타내고, 표로 나타내면 편리한 점을 말할 수 있다.  \n",
       "575615           분류한 자료를 표로 나타내고, 표로 나타내면 편리한 점을 말할 수 있다.  \n",
       "575616                                                NaN  \n",
       "\n",
       "[575617 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\GKT\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    learnerID assessmentItemID  answerCode  knowledgeTag  from_id  \\\n",
      "0  A030000005       A030001001           1           307    307.0   \n",
      "1  A030000005       A030001001           1           307    307.0   \n",
      "2  A030000005       A030001001           1           307    307.0   \n",
      "3  A030000005       A030001002           1           307    307.0   \n",
      "4  A030000005       A030001002           1           307    307.0   \n",
      "\n",
      "                     from_name from_semester  \\\n",
      "0  받아 내림이 없는 $(세 자릿수)-(세 자릿수)$     초등-초3-1학기   \n",
      "1  받아 내림이 없는 $(세 자릿수)-(세 자릿수)$     초등-초3-1학기   \n",
      "2  받아 내림이 없는 $(세 자릿수)-(세 자릿수)$     초등-초3-1학기   \n",
      "3  받아 내림이 없는 $(세 자릿수)-(세 자릿수)$     초등-초3-1학기   \n",
      "4  받아 내림이 없는 $(세 자릿수)-(세 자릿수)$     초등-초3-1학기   \n",
      "\n",
      "                                    from_description  from_chapter_id  \\\n",
      "0  1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...            149.0   \n",
      "1  1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...            149.0   \n",
      "2  1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...            149.0   \n",
      "3  1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...            149.0   \n",
      "4  1. 각 자리의 숫자를 맞추어 적습니다.\\n2. 일의 자리, 십의 자리, 백의 자리...            149.0   \n",
      "\n",
      "        from_chapter_name  from_achievement_id  \\\n",
      "0  덧셈과 뺄셈 > 뺄셈을 해 볼까요 (1)                 45.0   \n",
      "1  덧셈과 뺄셈 > 뺄셈을 해 볼까요 (1)                 45.0   \n",
      "2  덧셈과 뺄셈 > 뺄셈을 해 볼까요 (1)                 45.0   \n",
      "3  덧셈과 뺄셈 > 뺄셈을 해 볼까요 (1)                 45.0   \n",
      "4  덧셈과 뺄셈 > 뺄셈을 해 볼까요 (1)                 45.0   \n",
      "\n",
      "                               from_achievement_name   to_id        to_name  \\\n",
      "0  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  7797.0     (몇십 몇)-(몇)   \n",
      "1  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  7798.0      (몇십)-(몇십)   \n",
      "2  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  7799.0  (몇십 몇)-(몇십 몇)   \n",
      "3  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  7797.0     (몇십 몇)-(몇)   \n",
      "4  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  7798.0      (몇십)-(몇십)   \n",
      "\n",
      "  to_semester                                     to_description  \\\n",
      "0   초등-초1-2학기  (1) 낱개끼리  줄을 맞추어 씁니다.\\n(2) 낱개는 낱개끼리 빼고 10개씩 묶음...   \n",
      "1   초등-초1-2학기  (1) 10개씩 묶음은 10개씩 묶음끼리, 낱개는 낱개끼리 줄을 맞추어 씁니다.\\n...   \n",
      "2   초등-초1-2학기  (1) 10개씩 묶음은 10개씩 묶음끼리, 낱개는 낱개끼리 줄을 맞추어 씁니다.\\n...   \n",
      "3   초등-초1-2학기  (1) 낱개끼리  줄을 맞추어 씁니다.\\n(2) 낱개는 낱개끼리 빼고 10개씩 묶음...   \n",
      "4   초등-초1-2학기  (1) 10개씩 묶음은 10개씩 묶음끼리, 낱개는 낱개끼리 줄을 맞추어 씁니다.\\n...   \n",
      "\n",
      "   to_chapter_id            to_chapter_name  to_achievement_id  \\\n",
      "0           42.0  덧셈과 뺄셈(1) > 뺄셈을 해 볼까요 (1)               45.0   \n",
      "1           43.0  덧셈과 뺄셈(1) > 뺄셈을 해 볼까요 (2)               45.0   \n",
      "2           44.0  덧셈과 뺄셈(1) > 뺄셈을 해 볼까요 (3)               45.0   \n",
      "3           42.0  덧셈과 뺄셈(1) > 뺄셈을 해 볼까요 (1)               45.0   \n",
      "4           43.0  덧셈과 뺄셈(1) > 뺄셈을 해 볼까요 (2)               45.0   \n",
      "\n",
      "                                 to_achievement_name  \n",
      "0  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  \n",
      "1  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  \n",
      "2  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  \n",
      "3  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  \n",
      "4  두 자릿수의 범위에서 받아 올림이 없는 덧셈과 받아 내림이 없는 뺄셈의 계산 원리를...  \n",
      "Epoch 1, Loss: 0.7608\n",
      "Epoch 2, Loss: 0.4754\n",
      "Epoch 3, Loss: 0.6887\n",
      "Epoch 4, Loss: 0.6189\n",
      "Epoch 5, Loss: 0.6880\n",
      "Epoch 6, Loss: 0.6182\n",
      "Epoch 7, Loss: 0.4753\n",
      "Epoch 8, Loss: 0.6190\n",
      "Epoch 9, Loss: 0.5479\n",
      "Epoch 10, Loss: 0.4721\n",
      "Epoch 11, Loss: 0.6898\n",
      "Epoch 12, Loss: 0.5466\n",
      "Epoch 13, Loss: 0.6189\n",
      "Epoch 14, Loss: 0.5486\n",
      "Epoch 15, Loss: 0.3351\n",
      "Epoch 16, Loss: 0.6889\n",
      "Epoch 17, Loss: 0.4762\n",
      "Epoch 18, Loss: 0.4791\n",
      "Epoch 19, Loss: 0.7591\n",
      "Epoch 20, Loss: 0.6185\n",
      "Test Loss: 0.5972, Test Accuracy: 0.7155\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 데이터 불러오기\n",
    "label_data = pd.read_csv(r'D:\\다운로드\\label.csv')\n",
    "thirdstu_data = pd.read_csv(r'D:\\다운로드\\thirdstu.csv')\n",
    "\n",
    "# 데이터 전처리\n",
    "edges = label_data[['from_id', 'to_id']].drop_duplicates()\n",
    "nodes = pd.concat([edges['from_id'], edges['to_id']]).unique()\n",
    "learner_data = thirdstu_data[['learnerID', 'assessmentItemID', 'answerCode', 'knowledgeTag']]\n",
    "merged_data = learner_data.merge(label_data, left_on='knowledgeTag', right_on='from_id', how='left')\n",
    "print(merged_data.head())\n",
    "\n",
    "# 훈련 및 테스트 데이터 분리\n",
    "train_data, test_data = train_test_split(merged_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 그래프 생성\n",
    "graph = nx.DiGraph()\n",
    "graph.add_nodes_from(nodes)\n",
    "graph.add_edges_from(edges.values)\n",
    "\n",
    "# 임베딩 학습\n",
    "stellar_graph = StellarGraph.from_networkx(graph)\n",
    "rw = BiasedRandomWalk(stellar_graph)\n",
    "walks = rw.run(nodes=list(graph.nodes()), length=100, n=20, p=0.7, q=2.5)\n",
    "str_walks = [[str(n) for n in walk] for walk in walks]\n",
    "model = Word2Vec(str_walks, vector_size=128, window=7, min_count=1, sg=1, workers=-1)\n",
    "node_embeddings = {node: model.wv[str(node)] for node in graph.nodes()}\n",
    "\n",
    "# 임베딩 데이터를 활용한 입력 생성 함수\n",
    "def create_input_data(data, node_embeddings):\n",
    "    X = np.array([node_embeddings.get(str(item), np.zeros(128)) for item in data['assessmentItemID']])\n",
    "    y = data['answerCode'].values\n",
    "    return X, y\n",
    "\n",
    "# 훈련 및 테스트 데이터 준비\n",
    "X_train, y_train = create_input_data(train_data, node_embeddings)\n",
    "X_test, y_test = create_input_data(test_data, node_embeddings)\n",
    "\n",
    "# LSTM에 입력할 데이터를 3차원으로 변환\n",
    "X_train = np.expand_dims(X_train, axis=1)  # (batch_size, time_steps, features)\n",
    "X_test = np.expand_dims(X_test, axis=1)\n",
    "\n",
    "# PyTorch 데이터셋 및 데이터로더 생성\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# PyTorch 모델 정의\n",
    "class KSGKTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KSGKTModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=256, batch_first=True)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=256, num_heads=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.dropout = nn.Dropout(0.3)  # Dropout 추가\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = lstm_out.permute(1, 0, 2)  # LSTM output shape adjustment for attention\n",
    "        attn_output, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
    "        attn_output = attn_output.permute(1, 0, 2)  # Shape back to (batch, seq, feature)\n",
    "        flatten_out = self.flatten(attn_output)\n",
    "        x = torch.relu(self.fc1(flatten_out))\n",
    "        x = self.dropout(x)  # Dropout 사용\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# 모델 초기화\n",
    "model = KSGKTModel()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 학습률 변경 가능\n",
    "\n",
    "# 학습 및 평가 루프\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for data, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
    "\n",
    "def evaluate(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    loss_total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss_total += loss.item()\n",
    "            preds = (outputs.squeeze() > 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    return loss_total / len(test_loader), accuracy\n",
    "\n",
    "# 데이터 로더 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "train(model, train_loader, criterion, optimizer, num_epochs=20)\n",
    "loss, accuracy = evaluate(model, test_loader, criterion)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.5989, Test Loss: 0.5976, Test Accuracy: 0.7155\n",
      "Epoch 2, Train Loss: 0.5983, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 3, Train Loss: 0.5982, Test Loss: 0.5978, Test Accuracy: 0.7155\n",
      "Epoch 4, Train Loss: 0.5982, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 5, Train Loss: 0.5982, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 6, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 7, Train Loss: 0.5982, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 8, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 9, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 10, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 11, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 12, Train Loss: 0.5981, Test Loss: 0.5973, Test Accuracy: 0.7155\n",
      "Epoch 13, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 14, Train Loss: 0.5981, Test Loss: 0.5973, Test Accuracy: 0.7155\n",
      "Epoch 15, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 16, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 17, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 18, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 19, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 20, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 21, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 22, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 23, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 24, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 25, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 26, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 27, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 28, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 29, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 30, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 31, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 32, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 33, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 34, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 35, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 36, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 37, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 38, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 39, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 40, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 41, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 42, Train Loss: 0.5981, Test Loss: 0.5974, Test Accuracy: 0.7155\n",
      "Epoch 43, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 44, Train Loss: 0.5981, Test Loss: 0.5973, Test Accuracy: 0.7155\n",
      "Epoch 45, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 46, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 47, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 48, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 49, Train Loss: 0.5981, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "Epoch 50, Train Loss: 0.5980, Test Loss: 0.5972, Test Accuracy: 0.7155\n",
      "개념 '407'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 405 8006 8014 8015 8017 8019 8020 8021 8016 8018 8022  373]\n",
      "개념 '7653'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8122 7636]\n",
      "개념 '373'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8006 8014 8015 8017 8019 8020 8021 8016 8018]\n",
      "개념 '452'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 351  447 8122]\n",
      "개념 '409'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8006 8014 8015 8017 8019 8020 8021 8016 8018 8022  373  405]\n",
      "개념 '7636'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8006 8014 8015 8017 8019 8020 8021 8016 8018 8022  405]\n",
      "개념 '1982'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8138 8091]\n",
      "개념 '342'에 대한 충분한 이해를 기반으로 제안된 후수학습: [6804  332]\n",
      "개념 '371'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8006 8014 8015 8017 8019 8020 8021 8016 8018 8022]\n",
      "개념 '339'에 대한 충분한 이해를 기반으로 제안된 후수학습: [6805  332]\n",
      "개념 '334'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '465'에 대한 충분한 이해를 기반으로 제안된 후수학습: [5836 6648]\n",
      "개념 '405'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8006 8014 8015 8017 8019 8020 8021 8016 8018 8022]\n",
      "개념 '346'에 대한 충분한 이해를 기반으로 제안된 후수학습: [6804  332  342]\n",
      "개념 '332'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '7781'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7690]\n",
      "개념 '438'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8129 8131 8132 7807 8130]\n",
      "개념 '307'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7797 7798 7799]\n",
      "개념 '7823'에 대한 충분한 이해를 기반으로 제안된 후수학습: [547 559 355]\n",
      "개념 '439'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 438 8129 8130 8132]\n",
      "개념 '447'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 351 8122 8095 7333]\n",
      "개념 '7789'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7788]\n",
      "개념 '464'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 447 5814]\n",
      "개념 '429'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8124 7935]\n",
      "개념 '458'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 351  447 8122]\n",
      "개념 '559'에 대한 충분한 이해를 기반으로 제안된 후수학습: [554]\n",
      "개념 '1934'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7937]\n",
      "개념 '7308'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7307 7924]\n",
      "개념 '1873'에 대한 충분한 이해를 기반으로 제안된 후수학습: [452]\n",
      "개념 '1964'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '475'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '411'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8006 8014 8015 8017 8019 8020 8021 8016 8018 8022  407  409]\n",
      "개념 '7691'에 대한 충분한 이해를 기반으로 제안된 후수학습: [355 365]\n",
      "개념 '443'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 438  439 8129 8130 8132]\n",
      "개념 '436'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7935 7936 8124]\n",
      "개념 '1880'에 대한 충분한 이해를 기반으로 제안된 후수학습: [452]\n",
      "개념 '1721'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '7818'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7788 7789 7817]\n",
      "개념 '7334'에 대한 충분한 이해를 기반으로 제안된 후수학습: [351]\n",
      "개념 '1962'에 대한 충분한 이해를 기반으로 제안된 후수학습: [1934 7937]\n",
      "개념 '7788'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 371 7781]\n",
      "개념 '1727'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '1935'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7309  309 7310 1933]\n",
      "개념 '461'에 대한 충분한 이해를 기반으로 제안된 후수학습: [5836 6648]\n",
      "개념 '1984'에 대한 충분한 이해를 기반으로 제안된 후수학습: [1983 8135 8138]\n",
      "개념 '7333'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '1707'에 대한 충분한 이해를 기반으로 제안된 후수학습: [6806]\n",
      "개념 '7817'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '1931'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '481'에 대한 충분한 이해를 기반으로 제안된 후수학습: [5836 7918 8005 6648  475]\n",
      "개념 '1878'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '574'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7945 8122]\n",
      "개념 '308'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 307 7927 7928]\n",
      "개념 '7307'에 대한 충분한 이해를 기반으로 제안된 후수학습: [6776 7802]\n",
      "개념 '7690'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '419'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '7637'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8122 7636]\n",
      "개념 '1726'에 대한 충분한 이해를 기반으로 제안된 후수학습: [458]\n",
      "개념 '309'에 대한 충분한 이해를 기반으로 제안된 후수학습: [308]\n",
      "개념 '1875'에 대한 충분한 이해를 기반으로 제안된 후수학습: [5834 5814]\n",
      "개념 '355'에 대한 충분한 이해를 기반으로 제안된 후수학습: [363]\n",
      "개념 '1720'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '1876'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 452 1873]\n",
      "개념 '7782'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 371 7691]\n",
      "개념 '417'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '547'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '1728'에 대한 충분한 이해를 기반으로 제안된 후수학습: [1727]\n",
      "개념 '551'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '471'에 대한 충분한 이해를 기반으로 제안된 후수학습: [452]\n",
      "개념 '1963'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7309  309 7310 1961]\n",
      "개념 '554'에 대한 충분한 이해를 기반으로 제안된 후수학습: [411]\n",
      "개념 '365'에 대한 충분한 이해를 기반으로 제안된 후수학습: [363 355]\n",
      "개념 '7321'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '433'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '1874'에 대한 충분한 이해를 기반으로 제안된 후수학습: [1872]\n",
      "개념 '7829'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '363'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7598  351]\n",
      "개념 '1877'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 452 1873]\n",
      "개념 '1872'에 대한 충분한 이해를 기반으로 제안된 후수학습: [464]\n",
      "개념 '7309'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7308]\n",
      "개념 '7310'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7308 7309]\n",
      "개념 '351'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '331'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '1879'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '431'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17556\\3468450319.py:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data['predicted_proficiency'] = predictions\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 데이터 불러오기\n",
    "label_data = pd.read_csv(r'D:\\다운로드\\label.csv')\n",
    "thirdstu_data = pd.read_csv(r'D:\\다운로드\\thirdstu.csv')\n",
    "\n",
    "# 그래프 생성 및 임베딩 학습\n",
    "edges = label_data[['from_id', 'to_id']].drop_duplicates()\n",
    "graph = nx.DiGraph()\n",
    "graph.add_edges_from(edges.values)\n",
    "stellar_graph = StellarGraph.from_networkx(graph)\n",
    "\n",
    "rw = BiasedRandomWalk(stellar_graph)\n",
    "walks = rw.run(nodes=list(graph.nodes()), length=100, n=20, p=0.7, q=2.5)\n",
    "str_walks = [[str(n) for n in walk] for walk in walks]\n",
    "word2vec_model = Word2Vec(str_walks, vector_size=128, window=7, min_count=1, sg=1, workers=-1)\n",
    "node_embeddings = {node: word2vec_model.wv[str(node)] for node in graph.nodes()}\n",
    "\n",
    "# 학습자 평가 데이터 준비\n",
    "learner_data = thirdstu_data[['learnerID', 'assessmentItemID', 'answerCode', 'knowledgeTag']]\n",
    "merged_data = learner_data.merge(label_data, left_on='knowledgeTag', right_on='from_id', how='left')\n",
    "\n",
    "# 훈련 및 테스트 데이터 분리\n",
    "train_data, test_data = train_test_split(merged_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 준비 함수\n",
    "def create_input_data(data, node_embeddings):\n",
    "    X = np.array([node_embeddings.get(str(item), np.zeros(128)) for item in data['assessmentItemID']])\n",
    "    y = data['answerCode'].values\n",
    "    return X, y\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "X_train, y_train = create_input_data(train_data, node_embeddings)\n",
    "X_test, y_test = create_input_data(test_data, node_embeddings)\n",
    "\n",
    "# PyTorch 텐서로 변환\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # (batch_size, time_steps=1, features=128)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# DataLoader 정의\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# KSGKT 모델 정의\n",
    "class KSGKTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KSGKTModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=128, hidden_size=256, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=256, hidden_size=128, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=128, hidden_size=64, batch_first=True)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=64, num_heads=1, batch_first=True)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x, _ = self.attention(x, x, x)  # Q, K, V are all the LSTM output\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "# 모델 초기화\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = KSGKTModel().to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 정의\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 학습\n",
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "# 모델 평가\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return running_loss / len(loader), accuracy, np.array(all_predictions)\n",
    "\n",
    "# 학습 루프\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_accuracy, predictions = evaluate(model, test_loader, criterion, device)\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# 학습자의 지식 상태 예측\n",
    "test_data['predicted_proficiency'] = predictions\n",
    "\n",
    "# 특정 개념에 대해 학습자가 자주 틀리거나 낮은 예측 확률을 보이는 경우 식별\n",
    "def identify_weak_concepts(data, threshold=0.5):\n",
    "    weak_concepts = data[data['predicted_proficiency'] < threshold]['knowledgeTag'].unique()\n",
    "    return weak_concepts\n",
    "\n",
    "# 높은 이해도를 보이는 개념에 대한 후수학습 제시\n",
    "def suggest_followup_learning(concept_id, prerequisite_data):\n",
    "    return prerequisite_data[prerequisite_data['from_id'] == concept_id]['to_id'].values\n",
    "\n",
    "# 낮은 이해도를 보이는 개념에 대한 선수학습 제시\n",
    "def suggest_prerequisite_learning(concept_id, prerequisite_data):\n",
    "    return prerequisite_data[prerequisite_data['to_id'] == concept_id]['from_id'].values\n",
    "\n",
    "# 복습 제안: 반복적인 실수를 하는 개념 식별\n",
    "def suggest_review(data, error_threshold=0.3):\n",
    "    review_concepts = data[data['predicted_proficiency'] < error_threshold]['knowledgeTag'].unique()\n",
    "    return review_concepts\n",
    "\n",
    "# 학습자에게 제안할 선수 및 후수학습 결정\n",
    "weak_concepts = identify_weak_concepts(test_data)\n",
    "strong_concepts = test_data[test_data['predicted_proficiency'] >= 0.8]['knowledgeTag'].unique()\n",
    "review_concepts = suggest_review(test_data)\n",
    "\n",
    "# 제안된 학습 경로 출력\n",
    "for concept in weak_concepts:\n",
    "    prerequisites = suggest_prerequisite_learning(concept, label_data)\n",
    "    print(f\"개념 '{concept}'에 대한 부족한 이해를 보완하기 위해 제안된 선수학습: {prerequisites}\")\n",
    "\n",
    "for concept in strong_concepts:\n",
    "    followups = suggest_followup_learning(concept, label_data)\n",
    "    print(f\"개념 '{concept}'에 대한 충분한 이해를 기반으로 제안된 후수학습: {followups}\")\n",
    "\n",
    "for concept in review_concepts:\n",
    "    print(f\"개념 '{concept}'에 대한 반복적인 실수가 식별되어 복습을 제안합니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'threshold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# 특정 학습자의 학습 경로 제안 호출\u001b[39;00m\n\u001b[0;32m     38\u001b[0m learner_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA030000385\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# 예시 learnerID\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[43msuggest_learning_path_for_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearner_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m, in \u001b[0;36msuggest_learning_path_for_learner\u001b[1;34m(learner_id, test_data, label_data)\u001b[0m\n\u001b[0;32m      7\u001b[0m learner_data\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_proficiency\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m predictions[test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearnerID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m learner_id]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 특정 개념에 대해 학습자가 자주 틀리거나 낮은 예측 확률을 보이는 경우 식별\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m weak_concepts \u001b[38;5;241m=\u001b[39m identify_weak_concepts(learner_data, \u001b[43mthreshold\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m     11\u001b[0m strong_concepts \u001b[38;5;241m=\u001b[39m learner_data[learner_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_proficiency\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknowledgeTag\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m     12\u001b[0m review_concepts \u001b[38;5;241m=\u001b[39m suggest_review(learner_data, error_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'threshold' is not defined"
     ]
    }
   ],
   "source": [
    "# 특정 학습자에게 제안할 학습 경로 제공 함수\n",
    "def suggest_learning_path_for_learner(learner_id, test_data, label_data):\n",
    "    # 학습자의 데이터 필터링\n",
    "    learner_data = test_data[test_data['learnerID'] == learner_id].copy()\n",
    "\n",
    "    # 학습자의 지식 상태 예측 결과 추가\n",
    "    learner_data.loc[:, 'predicted_proficiency'] = predictions[test_data['learnerID'] == learner_id]\n",
    "\n",
    "    # 특정 개념에 대해 학습자가 자주 틀리거나 낮은 예측 확률을 보이는 경우 식별\n",
    "    weak_concepts = identify_weak_concepts(learner_data, threshold=0.2)\n",
    "    strong_concepts = learner_data[learner_data['predicted_proficiency'] >= 0.8]['knowledgeTag'].unique()\n",
    "    review_concepts = suggest_review(learner_data, error_threshold=0.3)\n",
    "\n",
    "    # 제안된 학습 경로 출력\n",
    "    print(f\"학습자 '{learner_id}'의 학습 경로 제안:\")\n",
    "    \n",
    "    if weak_concepts.size > 0:\n",
    "        for concept in weak_concepts:\n",
    "            prerequisites = suggest_prerequisite_learning(concept, label_data)\n",
    "            print(f\"개념 '{concept}'에 대한 부족한 이해를 보완하기 위해 제안된 선수학습: {prerequisites}\")\n",
    "    else:\n",
    "        print(\"선수학습을 제안할 개념이 없습니다.\")\n",
    "    \n",
    "    if strong_concepts.size > 0:\n",
    "        for concept in strong_concepts:\n",
    "            followups = suggest_followup_learning(concept, label_data)\n",
    "            print(f\"개념 '{concept}'에 대한 충분한 이해를 기반으로 제안된 후수학습: {followups}\")\n",
    "    else:\n",
    "        print(\"후수학습을 제안할 개념이 없습니다.\")\n",
    "    \n",
    "    if review_concepts.size > 0:\n",
    "        for concept in review_concepts:\n",
    "            print(f\"개념 '{concept}'에 대한 반복적인 실수가 식별되어 복습을 제안합니다.\")\n",
    "    else:\n",
    "        print(\"복습을 제안할 개념이 없습니다.\")\n",
    "\n",
    "# 특정 학습자의 학습 경로 제안 호출\n",
    "learner_id = 'A030000385'  # 예시 learnerID\n",
    "suggest_learning_path_for_learner(learner_id, test_data, label_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개념 '407'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 405 8006 8014 8015 8017 8019 8020 8021 8016 8018 8022  373]\n",
      "개념 '7653'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8122 7636]\n",
      "개념 '373'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8006 8014 8015 8017 8019 8020 8021 8016 8018]\n",
      "개념 '452'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 351  447 8122]\n",
      "개념 '409'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8006 8014 8015 8017 8019 8020 8021 8016 8018 8022  373  405]\n",
      "개념 '7636'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8006 8014 8015 8017 8019 8020 8021 8016 8018 8022  405]\n",
      "개념 '1982'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8138 8091]\n",
      "개념 '342'에 대한 충분한 이해를 기반으로 제안된 후수학습: [6804  332]\n",
      "개념 '371'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8006 8014 8015 8017 8019 8020 8021 8016 8018 8022]\n",
      "개념 '339'에 대한 충분한 이해를 기반으로 제안된 후수학습: [6805  332]\n",
      "개념 '334'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '465'에 대한 충분한 이해를 기반으로 제안된 후수학습: [5836 6648]\n",
      "개념 '405'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8006 8014 8015 8017 8019 8020 8021 8016 8018 8022]\n",
      "개념 '346'에 대한 충분한 이해를 기반으로 제안된 후수학습: [6804  332  342]\n",
      "개념 '332'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '7781'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7690]\n",
      "개념 '438'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8129 8131 8132 7807 8130]\n",
      "개념 '307'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7797 7798 7799]\n",
      "개념 '7823'에 대한 충분한 이해를 기반으로 제안된 후수학습: [547 559 355]\n",
      "개념 '439'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 438 8129 8130 8132]\n",
      "개념 '447'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 351 8122 8095 7333]\n",
      "개념 '7789'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7788]\n",
      "개념 '464'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 447 5814]\n",
      "개념 '429'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8124 7935]\n",
      "개념 '458'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 351  447 8122]\n",
      "개념 '559'에 대한 충분한 이해를 기반으로 제안된 후수학습: [554]\n",
      "개념 '1934'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7937]\n",
      "개념 '7308'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7307 7924]\n",
      "개념 '1873'에 대한 충분한 이해를 기반으로 제안된 후수학습: [452]\n",
      "개념 '1964'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '475'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '411'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8006 8014 8015 8017 8019 8020 8021 8016 8018 8022  407  409]\n",
      "개념 '7691'에 대한 충분한 이해를 기반으로 제안된 후수학습: [355 365]\n",
      "개념 '443'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 438  439 8129 8130 8132]\n",
      "개념 '436'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7935 7936 8124]\n",
      "개념 '1880'에 대한 충분한 이해를 기반으로 제안된 후수학습: [452]\n",
      "개념 '1721'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '7818'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7788 7789 7817]\n",
      "개념 '7334'에 대한 충분한 이해를 기반으로 제안된 후수학습: [351]\n",
      "개념 '1962'에 대한 충분한 이해를 기반으로 제안된 후수학습: [1934 7937]\n",
      "개념 '7788'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 371 7781]\n",
      "개념 '1727'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '1935'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7309  309 7310 1933]\n",
      "개념 '461'에 대한 충분한 이해를 기반으로 제안된 후수학습: [5836 6648]\n",
      "개념 '1984'에 대한 충분한 이해를 기반으로 제안된 후수학습: [1983 8135 8138]\n",
      "개념 '7333'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '1707'에 대한 충분한 이해를 기반으로 제안된 후수학습: [6806]\n",
      "개념 '7817'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '1931'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '481'에 대한 충분한 이해를 기반으로 제안된 후수학습: [5836 7918 8005 6648  475]\n",
      "개념 '1878'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '574'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7945 8122]\n",
      "개념 '308'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 307 7927 7928]\n",
      "개념 '7307'에 대한 충분한 이해를 기반으로 제안된 후수학습: [6776 7802]\n",
      "개념 '7690'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '419'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '7637'에 대한 충분한 이해를 기반으로 제안된 후수학습: [8122 7636]\n",
      "개념 '1726'에 대한 충분한 이해를 기반으로 제안된 후수학습: [458]\n",
      "개념 '309'에 대한 충분한 이해를 기반으로 제안된 후수학습: [308]\n",
      "개념 '1875'에 대한 충분한 이해를 기반으로 제안된 후수학습: [5834 5814]\n",
      "개념 '355'에 대한 충분한 이해를 기반으로 제안된 후수학습: [363]\n",
      "개념 '1720'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '1876'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 452 1873]\n",
      "개념 '7782'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 371 7691]\n",
      "개념 '417'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '547'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '1728'에 대한 충분한 이해를 기반으로 제안된 후수학습: [1727]\n",
      "개념 '551'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '471'에 대한 충분한 이해를 기반으로 제안된 후수학습: [452]\n",
      "개념 '1963'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7309  309 7310 1961]\n",
      "개념 '554'에 대한 충분한 이해를 기반으로 제안된 후수학습: [411]\n",
      "개념 '365'에 대한 충분한 이해를 기반으로 제안된 후수학습: [363 355]\n",
      "개념 '7321'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '433'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '1874'에 대한 충분한 이해를 기반으로 제안된 후수학습: [1872]\n",
      "개념 '7829'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '363'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7598  351]\n",
      "개념 '1877'에 대한 충분한 이해를 기반으로 제안된 후수학습: [ 452 1873]\n",
      "개념 '1872'에 대한 충분한 이해를 기반으로 제안된 후수학습: [464]\n",
      "개념 '7309'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7308]\n",
      "개념 '7310'에 대한 충분한 이해를 기반으로 제안된 후수학습: [7308 7309]\n",
      "개념 '351'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '331'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '1879'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n",
      "개념 '431'에 대한 충분한 이해를 기반으로 제안된 후수학습: []\n"
     ]
    }
   ],
   "source": [
    "# 특정 개념에 대해 학습자가 자주 틀리거나 낮은 예측 확률을 보이는 경우 식별\n",
    "def identify_weak_concepts(data, threshold=0.3):\n",
    "    weak_concepts = data[data['predicted_proficiency'] <= threshold]['knowledgeTag'].unique()\n",
    "    return weak_concepts\n",
    "\n",
    "# 학습자에게 제안할 선수 및 후수학습 결정\n",
    "weak_concepts = identify_weak_concepts(test_data, threshold=0.3)  # 여기에서 threshold를 0.3 이하로 변경\n",
    "strong_concepts = test_data[test_data['predicted_proficiency'] >= 0.9]['knowledgeTag'].unique()\n",
    "review_concepts = suggest_review(test_data)\n",
    "\n",
    "# 제안된 학습 경로 출력\n",
    "for concept in weak_concepts:\n",
    "    prerequisites = suggest_prerequisite_learning(concept, label_data)\n",
    "    print(f\"개념 '{concept}'에 대한 부족한 이해를 보완하기 위해 제안된 선수학습: {prerequisites}\")\n",
    "\n",
    "for concept in strong_concepts:\n",
    "    followups = suggest_followup_learning(concept, label_data)\n",
    "    print(f\"개념 '{concept}'에 대한 충분한 이해를 기반으로 제안된 후수학습: {followups}\")\n",
    "\n",
    "for concept in review_concepts:\n",
    "    print(f\"개념 '{concept}'에 대한 반복적인 실수가 식별되어 복습을 제안합니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GKT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
